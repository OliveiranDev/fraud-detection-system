# ğŸ›¡ï¸ Credit Card Fraud Detection System
## ğŸ“Œ VisÃ£o Geral do Projeto
Este projeto implementa um pipeline completo de Data Science para detecÃ§Ã£o de fraudes em transaÃ§Ãµes financeiras. O sistema foi desenhado sob a perspectiva de PrevenÃ§Ã£o de Perdas (Loss Prevention), equilibrando a precisÃ£o tÃ©cnica com as restriÃ§Ãµes operacionais e de experiÃªncia do usuÃ¡rio (UX).

## ğŸ“ˆ 1. Entendimento do Problema de NegÃ³cio
O objetivo central Ã© reduzir a taxa de chargeback sem elevar o atrito com clientes legÃ­timos.

KPI PrimÃ¡rio: Recall (Taxa de DetecÃ§Ã£o de Fraude).

KPI SecundÃ¡rio: False Positive Rate (FPR) para minimizar bloqueios indevidos.

RestriÃ§Ã£o Operacional: O time de revisÃ£o manual tem capacidade para apenas 50 casos/dia.

SLA TÃ©cnico: Tempo de resposta do modelo deve ser < 100ms para integraÃ§Ã£o em tempo real.


## ğŸ—ï¸ 2. Arquitetura do Pipeline de Dados
Seguimos a Medallion Architecture para garantir linhagem e governanÃ§a dos dados:

Bronze (Raw): Dados brutos ingeridos via Kaggle API, mantendo a integridade original.

Silver (Trusted): Dados convertidos para Apache Parquet via pyarrow. Nesta etapa, aplicamos padronizaÃ§Ã£o de schemas (snake_case) e garantimos a tipagem forte das variÃ¡veis.

Gold (Processed): (PrÃ³xima etapa) Dados limpos e enriquecidos prontos para o treinamento do modelo.


## ğŸ” 3. Mapeamento e DiagnÃ³stico (EDA Inicial)
Durante o profiling inicial dos dados (Fase 2), identificamos pontos crÃ­ticos para a estratÃ©gia de modelagem:

Extremo Desbalanceamento: Apenas 0.1727% das transaÃ§Ãµes sÃ£o fraudulentas (492 casos em 284.807).

Janela Temporal: O dataset cobre 48 horas de transaÃ§Ãµes.

Privacidade (LGPD): Dados anonimizados via PCA para proteÃ§Ã£o de PII (Personally Identifiable Information).


## ğŸ› ï¸ Tecnologias e Ferramentas

Linguagem: Python 3.12+.

ManipulaÃ§Ã£o de Dados: Pandas & PyArrow.

IngestÃ£o: Kaggle API (ExtraÃ§Ã£o AutomÃ¡tica).

DocumentaÃ§Ã£o: Notion & Miro (Design Doc).

## ğŸ“‚ Estrutura do Projeto
```text
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/          # Dados brutos (ImutÃ¡veis)
â”‚   â”œâ”€â”€ silver/       # Dados padronizados em Parquet
â”œâ”€â”€ src/
â”‚   â””â”€â”€ data/         # Scripts de processamento de dados
â”‚       â”œâ”€â”€ ingestion.py          # Download via API
â”‚       â”œâ”€â”€ ingestion_silver.py   # PadronizaÃ§Ã£o e conversÃ£o
â”‚       â””â”€â”€ profiling.py          # RelatÃ³rio de saÃºde dos dados
â”œâ”€â”€ requirements.txt  # DependÃªncias do projeto
â””â”€â”€ README.md


## ğŸš€ Como Executar
Configure suas credenciais do Kaggle nas variÃ¡veis de ambiente.

Instale as dependÃªncias: pip install -r requirements.txt.

Execute o pipeline de ingestÃ£o: python src/data/ingestion_silver.py.

## Autor
Rodrigo Neves